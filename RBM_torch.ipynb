{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shpcode/Restricted-Boltzmann-Machine-RBM-/blob/main/RBM_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SulsHC4il1cQ"
      },
      "source": [
        "\n",
        "This is an implementation restricted Boltzmann machine working with Gibbs sampling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8KeyMWsl1cO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torchvision.transforms import ToTensor\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4kHstHl1cT"
      },
      "source": [
        "Defining the class for Restricted Boltzmann Machine (RBM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvZgWeIVl1cT"
      },
      "outputs": [],
      "source": [
        "class RBM:\n",
        "    def __init__(self, n_visible, n_hidden):\n",
        "        # Initializing hyperparameters\n",
        "        self.n = n_visible\n",
        "        self.m = n_hidden\n",
        "        self.h_all = self.combi()  # Generating all possible binary combinations for hidden units\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.softplus = nn.Softplus()\n",
        "    def init(self, betha):\n",
        "        # Initializing model parameters\n",
        "        w = betha * nn.Parameter(torch.nn.init.normal_(torch.empty(self.n, self.m), mean=0.0, std=1))\n",
        "        b = betha * nn.Parameter(torch.nn.init.normal_(torch.empty(1, self.n), mean=0.0, std=0))\n",
        "        c = betha * nn.Parameter(torch.nn.init.normal_(torch.empty(1, self.m), mean=0.0, std=1))\n",
        "        return w, b, c\n",
        "    def combi(self):\n",
        "        # Generating all possible binary combinations for hidden units\n",
        "        lst = list(itertools.product([0, 1], repeat=self.m))\n",
        "        return torch.tensor(lst).float()\n",
        "    def prob_h_given_v(self, visible_states, w, c):\n",
        "        # Computing probability of hidden units given visible units (p(h|V))\n",
        "        return self.sig(torch.matmul(visible_states, w) + c)\n",
        "    def prob_v_given_h(self, hidden_states, w, b):\n",
        "        # Computing probability of visible units given hidden units (p(v|h))\n",
        "        return self.sig(torch.matmul(hidden_states, w.transpose(1, 0)) + b)\n",
        "\n",
        "    # Contracive Divergence update\n",
        "    def cd_update(self, lr, cd_k, visible_input, w, b, c):\n",
        "        batch_size = torch.tensor(visible_input.shape[0], dtype=float)\n",
        "\n",
        "        # Positive phase\n",
        "        h_probs = self.prob_h_given_v(visible_input, w, c)\n",
        "        h_0 = torch.bernoulli(h_probs)\n",
        "        positive_grads = torch.matmul(torch.transpose(visible_input, 2, 1), h_0)\n",
        "        h_states = h_0\n",
        "\n",
        "        # Contrastive Divergence iterations\n",
        "        for step in range(cd_k):\n",
        "            v_probs = self.prob_v_given_h(h_states, w, b)\n",
        "            v_states = torch.bernoulli(v_probs)\n",
        "            h_probs = self.prob_h_given_v(v_states, w, c)\n",
        "            h_states = torch.bernoulli(h_probs)\n",
        "        negative_grads = torch.matmul(torch.transpose(v_states, 2, 1), h_states)\n",
        "\n",
        "        # Update model parameters\n",
        "        w = w + lr * (positive_grads - negative_grads).sum(0)\n",
        "        b = b + lr * (visible_input - v_states).sum(0)\n",
        "        c = c + lr * (h_0 - h_states).sum(0)\n",
        "        return w, b, c\n",
        "\n",
        "    # Free energy calculation\n",
        "    def free_energy(self, input, w, b, c):\n",
        "        v_bias = torch.matmul(input, torch.t(b)).squeeze()\n",
        "        alpha = torch.matmul(input, w).squeeze() + torch.repeat_interleave(c, input.shape[0], 0)\n",
        "        return -(self.softplus(alpha).sum(1) + v_bias).mean()\n",
        "\n",
        "    # Log partition function calculation\n",
        "    def log_z(self, w, b, c):\n",
        "        exponent = []\n",
        "        for i in range(self.h_all.shape[0]):\n",
        "            h_bias = torch.matmul(self.h_all[i, :], torch.t(c)).squeeze()\n",
        "            alpha = (torch.matmul(w, self.h_all[i, :]) + b)\n",
        "            exponent.append([h_bias + self.softplus(alpha).sum()])\n",
        "        expo = torch.tensor(exponent)\n",
        "        expo_m = expo.max()\n",
        "        return torch.log(torch.exp(expo - expo_m).sum()) + expo_m\n",
        "\n",
        "    # Reconstruct visible units from hidden units\n",
        "    def reconstruct(self, input, w, b, c):\n",
        "        hidden_probs = self.prob_h_given_v(input, w, c)\n",
        "        hidden_states = torch.bernoulli(hidden_probs)\n",
        "        visible_probs = self.prob_v_given_h(hidden_states, w, b)\n",
        "        return visible_probs\n",
        "\n",
        "    # Reconstruction error calculation\n",
        "    def reconstruct_error(self, input, w, b, c):\n",
        "        hidden_probs = self.prob_h_given_v(input, w, c)\n",
        "        hidden_states = torch.bernoulli(hidden_probs)\n",
        "        visible_probs = self.prob_v_given_h(hidden_states, w, b)\n",
        "        return torch.mean(torch.square(input - visible_probs)).detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urybWxdpl1cU"
      },
      "source": [
        "Function to shuffle input pixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y13A1ull1cV"
      },
      "outputs": [],
      "source": [
        "def shuffel(input):\n",
        "    rand_input = torch.zeros_like(input)\n",
        "    for i in range(IMAGE_SIZE * IMAGE_SIZE):\n",
        "        pixel = input[:, 0, i]\n",
        "        rand_pixel = pixel[torch.randperm(50)]\n",
        "        rand_input[:, 0, i] = rand_pixel\n",
        "    return rand_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iOekNkjl1cW"
      },
      "source": [
        "Setting hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gP7eWDPl1cW"
      },
      "outputs": [],
      "source": [
        "betha = 0.001\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=50)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvVqgjhLl1cX"
      },
      "source": [
        "Preparing validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYnQnLDql1cY"
      },
      "outputs": [],
      "source": [
        "for valid, bla in validation_loader:\n",
        "    valid = torch.flatten(valid, start_dim=2, end_dim=3)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUcNBO_bl1cZ"
      },
      "source": [
        "Initializing RBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jntSWXRql1cZ"
      },
      "outputs": [],
      "source": [
        "rbm = RBM(n_visible=IMAGE_SIZE**2, n_hidden=16)\n",
        "w, b, c = rbm.init(betha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3iALJ7al1ca"
      },
      "source": [
        "Training RBM using Contrastive Divergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUXMWzhpl1ca"
      },
      "outputs": [],
      "source": [
        "lr = 0.01\n",
        "LL = []\n",
        "cd_k = 4\n",
        "error = []\n",
        "epochs = 10\n",
        "i = -1\n",
        "for epoch in range(epochs):\n",
        "    for x, y in train_loader:\n",
        "        input = torch.flatten(x, start_dim=2, end_dim=3)\n",
        "        input = shuffel(input)\n",
        "        i = i + 1\n",
        "        if i == 200 or i % 500 == 0:\n",
        "            LL.append([cd_k, -rbm.free_energy(valid, w, b, c) - rbm.log_z(w, b, c)])\n",
        "        w, b, c = rbm.cd_update(lr / (2 * epoch + 1), cd_k, input, w, b, c)\n",
        "        b = torch.zeros(b.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMn2qmkl1cb"
      },
      "source": [
        "Saving negative log-likelihood values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jp4Escjl1cb"
      },
      "outputs": [],
      "source": [
        "ll = np.asarray(LL)\n",
        "np.save('shuffel-neg-ll', ll)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0OCmnU7l1cb"
      },
      "source": [
        "Visualization of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIJLmbB_l1cc"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(2, 2)\n",
        "f.set_figheight(5)\n",
        "f.set_figwidth(5)\n",
        "axarr[0, 0].imshow(input[6, :, :].reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "axarr[0, 1].imshow(input[2, :, :].reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "axarr[1, 0].imshow(input[3, :, :].reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "axarr[1, 1].imshow(input[45, :, :].reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "plt.savefig('data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EJrWPRHl1cc"
      },
      "source": [
        "Generating new samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQgreHxgl1cc"
      },
      "outputs": [],
      "source": [
        "x = 1 * torch.flatten(validation_dataset[25][0]) + torch.normal(torch.zeros(IMAGE_SIZE**2), std=0.2)\n",
        "f, axarr = plt.subplots(1, 7)\n",
        "f.set_figheight(15)\n",
        "f.set_figwidth(15)\n",
        "axarr[0].imshow(x.reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "j = 0\n",
        "for i in range(120):\n",
        "    x = rbm.reconstruct(x, w, b, c)\n",
        "    if i % 20 == 0:\n",
        "        j = j + 1\n",
        "        im = x.detach().numpy()\n",
        "        axarr[j].imshow(im.reshape(IMAGE_SIZE, IMAGE_SIZE))\n",
        "        axarr[j].set_title('%i gibbs sampled' % i)\n",
        "plt.savefig('num-generat')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV_UPTJXl1cc"
      },
      "source": [
        "Plotting negative log-likelihood over updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf6aUhEcl1cd"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.asarray(LL)[:, 1])\n",
        "plt.ylabel('neg-ll')\n",
        "plt.xlabel('updates')\n",
        "plt.savefig('nn-ll')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXru-LQl1cd"
      },
      "source": [
        "Example of free energy calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prUm8Fiol1cd"
      },
      "outputs": [],
      "source": [
        "-rbm.free_energy(valid[1, 0, :], w, b, c) - rbm.log_z(w, b, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXuKtdhyl1ce"
      },
      "source": [
        "Generating samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmo0iIwvl1ce"
      },
      "outputs": [],
      "source": [
        "x = torch.randint(low=0, high=2, size=(1, IMAGE_SIZE**2)).float()\n",
        "chain = 10000\n",
        "for step in range(chain):\n",
        "    x = rbm.reconstruct(x, w, b, c)\n",
        "x = x.detach().numpy()\n",
        "plt.imshow(x.reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}