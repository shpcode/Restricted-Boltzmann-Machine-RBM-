{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shpcode/Restricted-Boltzmann-Machine-RBM-/blob/main/ais_rbm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpLcctniMnxs"
      },
      "source": [
        "import numpy as np\n",
        "# this class estimate log(Z) of an rbm model by Annealing Importance Sampling (AIS)\n",
        "\n",
        "''' in AIS we use chain of distributuion without knowing their normalization Z\n",
        "    consider unromlaized distribution as  p(v,beta)= exp(-E(v,beta))\n",
        "    -E(v,beta) = (1-beta) B*v + beta ( b*v + c*h + sum W*v*h )\n",
        "    first term of eneregy generating the trivial distribution and it is dominant at beta=0\n",
        "    second term is the true rbm distribution and it is dominant at beta= 1\n",
        "    AIS anneal from bete=0 to beta=1 to produce chain of distrubutins\n",
        "'''\n",
        "\n",
        "class AIS_rbm:\n",
        "\n",
        "  def __init__(self,v_dim,h_dim,the_rbm_model,visible_average_activity):\n",
        "    ''' initial parameters\n",
        "          v_dim >> number of visible units\n",
        "          h_dim >> number of hidden units\n",
        "          the_rbm_model >> parameters of rbm model that we want to estimate its log(z)\n",
        "                            insert as the_rbm_model =(w,b,c)\n",
        "                            where w is weights, b is visible bias , c is hidden bias\n",
        "                            with fallowing sizes [W]=(v_dim, h_dim) , [b]=(1,v_dim), [c]=(1,h_dim)\n",
        "\n",
        "          visible_average_activity >> we use this as the trivial ditribution to start sampling\n",
        "                                      for MINST dataset this means the average values of visivle units\n",
        "                                      over traning data set. shape: (1, v_dim)\n",
        "                                      '''\n",
        "    (self.w,self.b,self.c) = the_rbm_model\n",
        "    self.N_v = v_dim\n",
        "    self.N_h = h_dim\n",
        "\n",
        "    self.v_ave  =visible_average_activity\n",
        "    (self.B , self.log_z_0) = self.trivial_dist()\n",
        "\n",
        "\n",
        "  def trivial_dist(self,):\n",
        "    '''this is trivial distribution of visible units to start sampling.\n",
        "        here we set this equal to average activity of visible and compute trivial log_z_0 '''\n",
        "    B = -np.log(1/self.v_ave -1)\n",
        "    B[B==- np.inf]=-10\n",
        "    log_z_0 = self.N_h * np.log(2) +np.log(1+np.exp(B)).sum()\n",
        "    return B, log_z_0\n",
        "\n",
        "  def log_p_v(self, v, beta):\n",
        "    ''' ais compute ratio of chain of distributios. but it is easier to code log of this ration\n",
        "        this function compute unormalized p(v) for give beta'''\n",
        "    alpha = beta *(np.matmul(v,self.w).squeeze()+self.c.repeat(self.num_samples,0))\n",
        "    v_bias = (1 - beta) * np.matmul(v,self.B.T) + beta * np.matmul(v,self.b.T)\n",
        "    return np.log(1+np.exp(alpha)).sum(1,keepdims=True) + v_bias\n",
        "\n",
        "  def sample_v_given_h (self, h,beta):\n",
        "    e = beta*( np.matmul(h,self.w.transpose()) + self.b.repeat(self.num_samples,0)) + (1-beta)* self.B.repeat(self.num_samples,0)\n",
        "    p_v =  1 /(1+ np.exp( -e ))\n",
        "    return np.random.binomial(1,p_v)\n",
        "\n",
        "  def sample_h_given_v (self,v,beta):\n",
        "    e = beta*( (np.matmul(v,self.w).squeeze() + self.c.repeat(self.num_samples,0)) )\n",
        "    p_h =  1 /(1+ np.exp( -e ))\n",
        "    return np.random.binomial(1,p_h)\n",
        "\n",
        "  def log_sum_exp(self,x, axis=0):\n",
        "      alpha = x.max(axis) - np.log(np.finfo(np.float64).max) / 2.0\n",
        "      if axis == 1:\n",
        "          return np.squeeze(alpha + np.log(np.sum(np.exp(x.T - alpha), axis=0)))\n",
        "      else:\n",
        "          return np.squeeze(alpha + np.log(np.sum(np.exp(x - alpha), axis=0)))\n",
        "\n",
        "  def log_z(self,num_samples,anneal_steps,k):\n",
        "    ''' this function perfomr anneal steps and compute log_ratio to get log_z'''\n",
        "    self.num_samples = num_samples\n",
        "    betas =np.longdouble( np.linspace(0.0, 1.0,anneal_steps))\n",
        "\n",
        "    # first sample of v from trvial distribution\n",
        "    h = np.zeros((num_samples, self.N_h))\n",
        "    v = self.sample_v_given_h (h,betas[0])\n",
        "    log_ratio = - self.log_p_v(v,betas[0])\n",
        "\n",
        "    # anneal series of p_v(v,beta)\n",
        "    for beta in betas[1:betas.shape[0] - 1]:\n",
        "\n",
        "      log_ratio += self.log_p_v(v,beta)\n",
        "      ###\n",
        "      for _ in range(k):\n",
        "        h = self.sample_h_given_v (v,beta)\n",
        "        v = self.sample_v_given_h (h,beta)\n",
        "      ###\n",
        "      log_ratio -= self.log_p_v(v,beta)\n",
        "\n",
        "    log_ratio += self.log_p_v(v,betas[-1])\n",
        "\n",
        "    return self.log_sum_exp(log_ratio, axis=0) - np.log(self.num_samples) + self.log_z_0\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGtx9RSkMwWo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d22d085a-c389-4c16-ffd2-e97e93d427ae"
      },
      "source": [
        "''' How to use AIS_rbm\n",
        ">>read initial parameter inside AIS_rbm\n",
        ">> initialize the AIS_rbm parameters during traning rbm when computing log_z is desirable\n",
        ">>> then call method log_z to estimate log_z\n",
        "    method log_z takes three inputs\n",
        "1. num_samples is number of sample AIS do. set it 50\n",
        "2. anneal_steps is number step between 0 and 1 to anneal beta. normally 1000 steps, 100 is also worked\n",
        "3. k number of gibs chain. this is different from cd_k and traning rbm. set it 1 '''\n",
        "\n",
        "# # so each time you want to compute logz call fallowing\n",
        "# estimate = AIS_rbm(v_dim = 784 , h_dim =16,the_rbm_model=(w,b,c),visible_average_activity=v_m)\n",
        "# estimate.log_z(50,100,k=1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' How to use AIS_rbm\\n>>read initial parameter inside AIS_rbm\\n>> initialize the AIS_rbm parameters during traning rbm when computing log_z is desirable\\n>>> then call method log_z to estimate log_z\\n    method log_z takes three inputs\\n1. num_samples is number of sample AIS do. set it 50\\n2. anneal_steps is number step between 0 and 1 to anneal beta. normally 1000 steps, 100 is also worked\\n3. k number of gibs chain. this is different from cd_k and traning rbm. set it 1 '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}